{
  "model_name": "MassDetectionModel",
  "base_architecture": "DenseNet121",
  "task": "Binary Mass Detection",
  "date": "2025-11-20",
  "input": {
    "channels": 1,
    "height": 512,
    "width": 512,
    "format": "grayscale",
    "preprocessing": "CLAHE + normalization (see pipeline_config.json)"
  },
  "output": {
    "classes": 1,
    "format": "logit",
    "activation": "none (use BCEWithLogitsLoss)",
    "interpretation": "P(Mass) when sigmoid applied"
  },
  "architecture": {
    "backbone": "DenseNet121 (pretrained ImageNet)",
    "modifications": {
      "first_layer": {
        "original": "Conv2d(3, 64, 7x7)",
        "modified": "Conv2d(1, 64, 7x7)",
        "weights": "averaged from RGB channels"
      },
      "classifier_head": {
        "layers": [
          "AdaptiveAvgPool2d(1, 1)",
          "Flatten()",
          "Dropout(0.4)",
          "Linear(1024, 1)"
        ],
        "initialization": "He/Kaiming for Linear, zeros for bias"
      }
    },
    "parameters": {
      "total": 6948609,
      "total_millions": 6.95,
      "trainable_stage1": "~2M (head only)",
      "trainable_stage2": "~4M (head + last block)",
      "trainable_stage3": "~6M (full model)"
    }
  },
  "regularization": {
    "dropout": 0.4,
    "location": "before final Linear layer",
    "weight_decay": "1e-4 (in optimizer)",
    "batch_norm": "included in DenseNet blocks"
  },
  "transfer_learning": {
    "stage_1_feature_extraction": {
      "name": "Feature Extraction",
      "epochs": 5,
      "freeze_backbone": true,
      "learning_rate": {
        "backbone": 0.0,
        "head": 0.001
      },
      "description": "Train only classification head, backbone frozen"
    },
    "stage_2_partial_finetuning": {
      "name": "Partial Fine-tuning",
      "epochs": 10,
      "freeze_backbone": "partial",
      "learning_rate": {
        "backbone": 0.0001,
        "head": 0.001
      },
      "description": "Unfreeze last DenseBlock + transition, fine-tune high-level features"
    },
    "stage_3_full_finetuning": {
      "name": "Full Fine-tuning",
      "epochs": 15,
      "freeze_backbone": false,
      "learning_rate": {
        "backbone": 1e-05,
        "head": 0.001
      },
      "description": "Unfreeze entire network, full fine-tuning on Mass patterns"
    }
  },
  "training_strategy": {
    "total_epochs": 30,
    "stage_1": "5 epochs (head only)",
    "stage_2": "10 epochs (partial)",
    "stage_3": "15 epochs (full)",
    "early_stopping": {
      "patience": 5,
      "metric": "val_auc",
      "mode": "max"
    }
  },
  "loss_function": {
    "name": "BCEWithLogitsLoss",
    "pos_weight": 19.4,
    "reason": "Binary classification with class imbalance (Mass:NoMass = 1:19.4)"
  },
  "optimizer": {
    "name": "AdamW",
    "betas": [
      0.9,
      0.999
    ],
    "weight_decay": 0.0001,
    "differential_lr": {
      "stage_1": {
        "backbone": 0.0,
        "head": 0.001
      },
      "stage_2": {
        "backbone": 0.0001,
        "head": 0.001
      },
      "stage_3": {
        "backbone": 1e-05,
        "head": 0.001
      }
    }
  },
  "lr_scheduler": {
    "type": "ReduceLROnPlateau",
    "mode": "max",
    "factor": 0.5,
    "patience": 3,
    "min_lr": 1e-07
  }
}